[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog I do not understand"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "Optimization algorithms based on the gradients of functions.\n\n\n\n\n\n\nFeb 26, 2023\n\n\nTrong Le\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nIn this blog post, I will implement the perceptron algorithm using numerical programming and demonstrate its use on synthetic data sets.\n\n\n\n\n\n\nFeb 19, 2023\n\n\nTrong Le\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nAn example blog post illustrating the key techniques you’ll need to demonstrate your learning in CSCI 0451.\n\n\n\n\n\n\nJan 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/example-blog-post/index.html",
    "href": "posts/example-blog-post/index.html",
    "title": "Hello Blog",
    "section": "",
    "text": "beta*(w_tilda - w_tilda_prev) # this is w_{k+1} w_tilda_prev = w_tilda # this is w_{k-1} w_tilda = w_tilda_new # this is w_{k}\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/example-blog-post/index.html#math",
    "href": "posts/example-blog-post/index.html#math",
    "title": "Hello Blog",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/perceptron/perceptron.html",
    "href": "posts/perceptron/perceptron.html",
    "title": "Implementing the Perceptron Algorithm",
    "section": "",
    "text": "The primary method of the Perceptron class is Perceptron.fit(X, y). \\(\\textbf{X} \\in \\mathbb{R}^{n\\times p}\\) is a matrix of predictor variables, with \\(n\\) observations and \\(p\\) features, and \\(\\textbf{y} \\in {0, 1}^n\\) is a vector of binary labels. When the method Perceptron.fit(X, y) is called, the perceptron in question will get an instance variable of weights called w, and a history of the perceptron’s accuracy scores during the runtime of the function, called history.\nBefore updating the perceptron’s weight, we rewrite the problem with \\(\\tilde{\\textbf{X}} = [ \\textbf{X}, \\textbf{1} ]\\) and \\(\\tilde{\\textbf{w}} = (\\textbf{w}, - b)\\) to account for the bias. The perceptron algorithm is implemented as follows:\n\nWe start by assigning a random weight vector \\(\\tilde{\\textbf{w}}^{(0)}\\).\nUntil the perceptron achieves perfect accuracy (or until termination), in each time step t:\n\nPick a random point index \\(i\\) in \\(\\textbf{y}\\)\nUpdate the weight: \\[\\tilde{\\textbf{w}}^{(t+1)} = \\tilde{\\textbf{w}}^{(t)} + \\mathbb{1}(\\tilde{y}_i \\langle \\tilde{\\textbf{w}}^{(t)}, \\tilde{x}_i \\rangle < 0) \\tilde{y}_i \\tilde{x}_i,\\] where \\(\\tilde{y}_i = 2y_i -1\\), which takes on values of -1 and 1 instead of 0 and 1. The Boolean function in this equation checks whether or not the weight needs an update. It does not update when \\(\\tilde{y}_i \\langle \\tilde{\\textbf{w}}^{(t)}, \\tilde{x}_i \\rangle \\geq 0\\), which means that the prediction value matches the real value.\n\n\nWe will use this algorithm to conduct a few experiments, and confirm that if a set of data is linearly separable, this algorithm will separate the data.\n\nExperiment 1\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.datasets import make_blobs\n\nnp.random.seed(12345)\n\nn = 100\np_features = 3\n\nX, y = make_blobs(n_samples = 100, n_features = p_features - 1, centers = [(-1.7, -1.7), (1.7, 1.7)])\n\nfig = plt.scatter(X[:,0], X[:,1], c = y)\nxlab = plt.xlabel(\"Feature 1\")\nylab = plt.ylabel(\"Feature 2\")\n\n\n\n\nIn this experiment, our data have 2 features, and we can see that they are linearly separable. First, we import the Perceptron class from the code that I wrote. After calling the Perceptron.fit(X, y) method, we will find a weight vector \\(\\tilde{\\textbf{w}}\\) that describes the separating line.\n\nfrom perceptron import Perceptron\n\n\np = Perceptron()\np.fit(X, y, max_steps = 1000)\n\n\ndef draw_line(w, x_min, x_max):\n  x = np.linspace(x_min, x_max, 101)\n  y = -(w[0]*x + w[2])/w[1]\n  plt.plot(x, y, color = \"black\")\n\nfig = plt.scatter(X[:,0], X[:,1], c = y)\nfig = draw_line(p.w, -2, 2)\n\nxlab = plt.xlabel(\"Feature 1\")\nylab = plt.ylabel(\"Feature 2\")\n\n\n\n\n\n\nfig = plt.plot(p.history)\nxlab = plt.xlabel(\"Iteration\")\nylab = plt.ylabel(\"Accuracy\")\n\n\n\n\nGiven this set of linearly separable data, over time, our perceptron was able to separate the data with 100% accuracy. This was achieved within under 200 time steps.\n\n\nExperiment 2\n\nnp.random.seed(12345)\n\nn = 100\np_features = 3\n\nX, y = make_blobs(n_samples = 100, n_features = p_features - 1, centers = [(-1.7, -1.7), (0,0)])\n\nfig = plt.scatter(X[:,0], X[:,1], c = y)\nxlab = plt.xlabel(\"Feature 1\")\nylab = plt.ylabel(\"Feature 2\")\n\n\n\n\nIn this experiment, the data overlap each other, which makes them linearly inseparable. If we implement the perceptron algorithm in this case, the method Perceptron.fit(X, y) until it terminates, but its accuracy will never achieve 100%.\n\np = Perceptron()\np.fit(X, y, max_steps = 1000)\n\nfig = plt.scatter(X[:,0], X[:,1], c = y)\nfig = draw_line(p.w, -2, 2)\n\nxlab = plt.xlabel(\"Feature 1\")\nylab = plt.ylabel(\"Feature 2\")\n\n\n\n\n\nfig = plt.plot(p.history)\nxlab = plt.xlabel(\"Iteration\")\nylab = plt.ylabel(\"Accuracy\")\n\n\n\n\nBecause the perceptron algorithm never reached an accuracy of 100%, it was iterated 1000 times until it terminated. This is one of the limitations of the perceptron algorithm.\n\n\nExperiment 3\n\nnp.random.seed(12345)\n\nn = 100\np_features = 8\n\nX, y = make_blobs(n_samples = 100, n_features = p_features - 1, centers = 7)\n\nIn this case, we consider 7 features. Because the data set is no longer 2-dimensional, visualization is not possible. There are 7 centers spread randomly in the \\(\\mathbb{R}^7\\) space, each of which is surrounded by a cluster of one feature.\n\np = Perceptron()\np.fit(X, y, max_steps = 1000)\nfig = plt.plot(p.history)\nxlab = plt.xlabel(\"Iteration\")\nylab = plt.ylabel(\"Accuracy\")\n\n\n\n\nThe history of this perceptron indicates that this data set is not linearly separable because the accuracy of the perceptron never reaches 100%, and the algorithm runs for too long.\n\n\nRuntime Complexity\nWe are concerned with the runtime complexity of a single iteration of the perceptron algorithm update. We assume that the relevant operations are addition and multiplication. According to the update function, the operation that takes up the most time is the dot product between \\(\\tilde{\\textbf{w}}\\) and \\(\\tilde{\\textbf{x}}_i\\). Each of these terms has length \\(p+1\\) (\\(p\\) is the number of features). This is a sum of \\(p+1\\) products, which means that this update function has a time complexity of \\(\\mathcal{O}(p)\\). This depends only on the number of features, and not the number of data points."
  },
  {
    "objectID": "posts/gradient/gradient.html",
    "href": "posts/gradient/gradient.html",
    "title": "Gradient Descent",
    "section": "",
    "text": "Below is our data, which is not linearly separable.\n\nfrom solutions import LogisticRegression\nfrom sklearn.datasets import make_blobs\nfrom matplotlib import pyplot as plt\nimport numpy as np\nnp.seterr(all='ignore') \n\n# make the data\np_features = 3\nX, y = make_blobs(n_samples = 500, n_features = p_features - 1, centers = [(-1, -1), (1, 1)])\n\nfig = plt.scatter(X[:,0], X[:,1], c = y)\nxlab = plt.xlabel(\"Feature 1\")\nylab = plt.ylabel(\"Feature 2\")\n\n\n\n\n\n1. Gradient Descent\nThe gradient descent algorithm is implemented when the LogisticRegression.fit(X, y) is called. \\(\\textbf{X}\\) is the feature matrix, and \\(\\textbf{y}\\) is the target vector, as we know from the perceptron blog post. We need to find a weight vector that can minimize the logistic loss on \\(\\textbf{X}\\) and \\(\\textbf{y}\\) by updating the weight in a loop. At every loop:\n\ncompute the gradient descent of the logistic loss, which is given by \\[\\nabla L(\\textbf{w}) = \\frac{1}{n} \\sum^n_{i=1} (\\sigma (\\langle \\textbf{w}, \\textbf{x}_i \\rangle), y_i) \\textbf{w}_i, \\] where \\(\\sigma(z)\\) denotes the sigmoid function.\nupdate the weight until the logistic loss does not change \\[\\textbf{w}^{(t+1)} = \\textbf{w}^{(t)} - \\alpha \\nabla L(\\textbf{w}^{(t)})\\]\n\n\n# fit the model\n\nLR = LogisticRegression()\nLR.fit(X, y, alpha = 10, max_epochs = 1000)\n\n# inspect the fitted value of w\nLR.w \n\ndef draw_line(w, x_min, x_max):\n  x = np.linspace(x_min, x_max, 101)\n  y = -(w[0]*x + w[2])/w[1]\n  plt.plot(x, y, color = \"black\")\n\nfigy, axy = plt.subplots()\naxy.scatter(X[:,0], X[:,1], c = y)\ndraw_line(LR.w, -2, 2)\naxy.set_xlabel(\"Feature 1\")\naxy.set_ylabel(\"Feature 2\")\n\nfigx, axv = plt.subplots()\naxv.plot(LR.loss_history)\naxv.set_xlabel(\"Iteration\")\naxv.set_ylabel(\"Empirical Risk\")\nplt.show()\n\n\n\n\n\n\n\nIn this case, the learning rate was set very high to 10, which caused the algorithm to converge too soon and leave the logistic loss at 0.30. As we change the learning rate to 0.1, we can see that the loss fell to 0.27.\n\nLR = LogisticRegression()\nLR.fit(X, y, alpha=0.1, max_epochs=1000)\n\nfigy, axy = plt.subplots()\naxy.scatter(X[:,0], X[:,1], c = y)\ndraw_line(LR.w, -2, 2)\naxy.set_xlabel(\"Feature 1\")\naxy.set_ylabel(\"Feature 2\")\n\nfigx, axv = plt.subplots()\naxv.plot(LR.loss_history)\naxv.set_xlabel(\"Iteration\")\naxv.set_ylabel(\"Empirical Risk\")\nplt.show()\n\n\n\n\n\n\n\n\n\n2. Stochastic Gradient Descent\nThe stochastic gradient descent algorithm is implemented by the LogisticRegression.fit_stochastic(X, y) method. In this algorithm, instead of computing the complete gradient as in part 1, we compute a stochastic gradient by picking a random subset \\(S \\subseteq [n] = \\{1, ..., n\\}\\) and computing\n\\[\\nabla_S L(\\textbf{w}) = \\frac{1}{|S|} \\sum_{i \\in S} \\nabla (\\sigma (\\langle \\textbf{w}, \\textbf{x}_i \\rangle), y_i)\\textbf{x}_i \\]\nThe size of \\(S\\) is the batch size, which we can refer to as \\(k\\). The batch gradient descent is performed as follows: 1. Shuffle the points randomly. 2. Pick the first \\(k\\) random points, compute the stochastic gradient, and then perform an update. 3. Pick the next \\(k\\) random points and repeat.. 4. When we have gone through all \\(n\\) points, reshuffle them all randomly and proceed again.\n\nnp.seterr(all='ignore') \n\n# make the data\np_features = 3\nX, y = make_blobs(n_samples = 200, n_features = p_features - 1, centers = [(-1, -1), (1, 1)])\n\nfig = plt.scatter(X[:,0], X[:,1], c = y)\nxlab = plt.xlabel(\"Feature 1\")\nylab = plt.ylabel(\"Feature 2\")\n\n\n\n\nIn this experiment, we can see how the stochastic gradient descent algorithm can outperform the original gradient descent method.\n\nLR = LogisticRegression()\nLR.fit_stochastic(X, y, \n                  m_epochs = 100, \n                  momentum = False, \n                  batch_size = 10, \n                  alpha = .1)\n\nnum_steps = len(LR.loss_history)\nplt.plot(np.arange(num_steps) + 1, LR.loss_history, label = \"stochastic gradient\")\n\nLR = LogisticRegression()\nLR.fit(X, y, alpha = .1, max_epochs = 100)\n\nnum_steps = len(LR.loss_history)\nplt.plot(np.arange(num_steps) + 1, LR.loss_history, label = \"gradient\")\nplt.xlabel(\"Iteration\")\nplt.ylabel(\"Empirical Risk\")\nlegend = plt.legend() \n\n\n\n\nThe stochastic gradient method used only 25 loops, while the gradient method still had not converged at loop 100.\n\n\n3. Stochastic Gradient Descent with Momentum\nThis only difference in this method comes from the momentum factor \\(\\beta\\). The weight update is given by\n\\[\\textbf{w}^{(t+1)} = \\textbf{w}^{(t)} - \\alpha \\nabla L(\\textbf{w}^{(t)}) + \\beta (\\textbf{w}^{(t)}-\\textbf{w}^{(t-1)})\\]\nThe idea here is that if the previous weight update was good, we may want to continue moving along this direction. To test how the momentum can help with accelerating convergence, we choose a small sample size of 150, distributed among 10 features.\n\nnp.seterr(all='ignore') \n\n# make the data\np_features = 11\nX, y = make_blobs(n_samples = 150, n_features = p_features - 1, centers = [(-1, -1), (1, 1)])\n\nfig = plt.scatter(X[:,0], X[:,1], c = y)\nxlab = plt.xlabel(\"Feature 1\")\nylab = plt.ylabel(\"Feature 2\")\n\n\n\n\n\nLR = LogisticRegression()\nLR.fit_stochastic(X, y, \n                  m_epochs = 100, \n                  momentum = True, \n                  batch_size = 10, \n                  alpha = .1) \n\nnum_steps = len(LR.loss_history)\nplt.plot(np.arange(num_steps) + 1, LR.loss_history, label = \"stochastic gradient (momentum)\")\n\n\nLR = LogisticRegression()\nLR.fit_stochastic(X, y, \n                  m_epochs = 100, \n                  momentum = False, \n                  batch_size = 10, \n                  alpha = .1)\n\nnum_steps = len(LR.loss_history)\nplt.plot(np.arange(num_steps) + 1, LR.loss_history, label = \"stochastic gradient\")\nlegend = plt.legend() \nplt.xlabel(\"Iteration\")\nplt.ylabel(\"Empirical Risk\")\nplt.show()\n\n\n\n\nThe momentum algorithm converges in less than a quarter of the loops it takes the other method."
  }
]